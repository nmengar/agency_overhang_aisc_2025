{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1c91a9d776394ddb82585a8421c8f5e0": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_0d830094452b4d3783bc55f15b24c715",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "╭─ \u001b[1marc_challenge (1,172 samples): openai/gpt-4o-mini\u001b[0m ─────────────────────────────────────────────────────────────╮\n│                                                                                        dataset: allenai/ai2_arc │\n│                                                                                                                 │\n│ \u001b[1mtotal time:               \u001b[0m  0:02:23                                                                             │\n│ \u001b[1mopenai/gpt-4o-mini        \u001b[0m  132,769 tokens [\u001b[1mI: \u001b[0m125,227, \u001b[1mCW: \u001b[0m0, \u001b[1mCR: \u001b[0m0, \u001b[1mO: \u001b[0m7,542, \u001b[1mR: \u001b[0m0]                           │\n│                                                                                                                 │\n│ \u001b[1maccuracy: 0.922\u001b[0m  \u001b[1mstderr: 0.00786\u001b[0m                                                                                │\n│                                                                                                                 │\n│ \u001b[1mLog:\u001b[0m \u001b]8;id=640918;logs/2025-03-30T03-58-53+00-00_arc-challenge_76xCTibxeTTJViVknTFd9g.json\u001b\\logs/2025-03-30T03-58-53+00-00_arc-challenge_76xCTibxeTTJViVknTFd9g.json\u001b]8;;\u001b\\                                   │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">arc_challenge (1,172 samples): openai/gpt-4o-mini</span> ─────────────────────────────────────────────────────────────╮\n│      <span style=\"color: #000080; text-decoration-color: #000080\">                                                                                  dataset: allenai/ai2_arc</span> │\n│                                                                                                                 │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">total time:               </span><span style=\"color: #808080; text-decoration-color: #808080\">  0:02:23                                                                            </span> │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">openai/gpt-4o-mini        </span><span style=\"color: #808080; text-decoration-color: #808080\">  132,769 tokens [</span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">I: </span><span style=\"color: #808080; text-decoration-color: #808080\">125,227, </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">CW: </span><span style=\"color: #808080; text-decoration-color: #808080\">0, </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">CR: </span><span style=\"color: #808080; text-decoration-color: #808080\">0, </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">O: </span><span style=\"color: #808080; text-decoration-color: #808080\">7,542, </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">R: </span><span style=\"color: #808080; text-decoration-color: #808080\">0]                          </span> │\n│                                                                                                                 │\n│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">accuracy: 0.922</span><span style=\"color: #008000; text-decoration-color: #008000\">  </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">stderr: 0.00786</span>                                                                                │\n│                                                                                                                 │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">Log:</span> <a href=\"logs/2025-03-30T03-58-53+00-00_arc-challenge_76xCTibxeTTJViVknTFd9g.json\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080\">logs/2025-03-30T03-58-53+00-00_arc-challenge_76xCTibxeTTJViVknTFd9g.json</span></a>                                   │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "0d830094452b4d3783bc55f15b24c715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47a6bc62a5cc448d8ce6bc81cc2d7414": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_a9a74974747c4edf9b2e9f604f16be75",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "╭─ \u001b[1marc_challenge (1,172 samples): anthropic/claude-3-5-haiku-20241022\u001b[0m ────────────────────────────────────────────╮\n│                                                                                        dataset: allenai/ai2_arc │\n│                                                                                                                 │\n│ \u001b[1mtotal time:                                  \u001b[0m  0:02:57                                                          │\n│ \u001b[1manthropic/claude-3-5-haiku-20241022          \u001b[0m  149,480 tokens [\u001b[1mI: \u001b[0m141,276, \u001b[1mCW: \u001b[0m0, \u001b[1mCR: \u001b[0m0, \u001b[1mO: \u001b[0m8,204]              │\n│                                                                                                                 │\n│ \u001b[1maccuracy: 0.902\u001b[0m  \u001b[1mstderr: 0.00869\u001b[0m                                                                                │\n│                                                                                                                 │\n│ \u001b[1mLog:\u001b[0m \u001b]8;id=609517;logs/2025-03-30T04-01-18+00-00_arc-challenge_VnH5w7ZhA8mrVcn4yr7Bsm.json\u001b\\logs/2025-03-30T04-01-18+00-00_arc-challenge_VnH5w7ZhA8mrVcn4yr7Bsm.json\u001b]8;;\u001b\\                                   │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">arc_challenge (1,172 samples): anthropic/claude-3-5-haiku-20241022</span> ────────────────────────────────────────────╮\n│      <span style=\"color: #000080; text-decoration-color: #000080\">                                                                                  dataset: allenai/ai2_arc</span> │\n│                                                                                                                 │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">total time:                                  </span><span style=\"color: #808080; text-decoration-color: #808080\">  0:02:57                                                         </span> │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">anthropic/claude-3-5-haiku-20241022          </span><span style=\"color: #808080; text-decoration-color: #808080\">  149,480 tokens [</span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">I: </span><span style=\"color: #808080; text-decoration-color: #808080\">141,276, </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">CW: </span><span style=\"color: #808080; text-decoration-color: #808080\">0, </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">CR: </span><span style=\"color: #808080; text-decoration-color: #808080\">0, </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">O: </span><span style=\"color: #808080; text-decoration-color: #808080\">8,204]             </span> │\n│                                                                                                                 │\n│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">accuracy: 0.902</span><span style=\"color: #008000; text-decoration-color: #008000\">  </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">stderr: 0.00869</span>                                                                                │\n│                                                                                                                 │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">Log:</span> <a href=\"logs/2025-03-30T04-01-18+00-00_arc-challenge_VnH5w7ZhA8mrVcn4yr7Bsm.json\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080\">logs/2025-03-30T04-01-18+00-00_arc-challenge_VnH5w7ZhA8mrVcn4yr7Bsm.json</span></a>                                   │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "a9a74974747c4edf9b2e9f604f16be75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea32df1816594e9d89f26e891b11060b": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_bf57d77658634f4082413d175fb8ff9c",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "╭─ \u001b[1marc_challenge (1,172 samples): groq/llama3-8b-8192\u001b[0m ────────────────────────────────────────────────────────────╮\n│                                                                                        dataset: allenai/ai2_arc │\n│ \u001b[1mtotal time:                \u001b[0m  0:14:43                                                                            │\n│ \u001b[1mopenai/gpt-4o-mini         \u001b[0m  456,004 tokens [\u001b[1mI: \u001b[0m242,198, \u001b[1mCW: \u001b[0m0, \u001b[1mCR: \u001b[0m0, \u001b[1mO: \u001b[0m213,806, \u001b[1mR: \u001b[0m0]                        │\n│ \u001b[1mgroq/llama3-8b-8192        \u001b[0m  322,735 tokens [\u001b[1mI: \u001b[0m316,861, \u001b[1mO: \u001b[0m5,874]                                              │\n│                                                                                                                 │\n│ \u001b[1maccuracy: 0.825\u001b[0m  \u001b[1mstderr: 0.0111\u001b[0m                                                                                 │\n│                                                                                                                 │\n│ \u001b[1mLog:\u001b[0m \u001b]8;id=704993;logs/2025-03-30T05-41-24+00-00_arc-challenge_3rxBdeeDZHy6PzDrYAc29G.json\u001b\\logs/2025-03-30T05-41-24+00-00_arc-challenge_3rxBdeeDZHy6PzDrYAc29G.json\u001b]8;;\u001b\\                                   │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">arc_challenge (1,172 samples): groq/llama3-8b-8192</span> ────────────────────────────────────────────────────────────╮\n│      <span style=\"color: #000080; text-decoration-color: #000080\">                                                                                  dataset: allenai/ai2_arc</span> │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">total time:                </span><span style=\"color: #808080; text-decoration-color: #808080\">  0:14:43                                                                           </span> │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">openai/gpt-4o-mini         </span><span style=\"color: #808080; text-decoration-color: #808080\">  456,004 tokens [</span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">I: </span><span style=\"color: #808080; text-decoration-color: #808080\">242,198, </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">CW: </span><span style=\"color: #808080; text-decoration-color: #808080\">0, </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">CR: </span><span style=\"color: #808080; text-decoration-color: #808080\">0, </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">O: </span><span style=\"color: #808080; text-decoration-color: #808080\">213,806, </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">R: </span><span style=\"color: #808080; text-decoration-color: #808080\">0]                       </span> │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">groq/llama3-8b-8192        </span><span style=\"color: #808080; text-decoration-color: #808080\">  322,735 tokens [</span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">I: </span><span style=\"color: #808080; text-decoration-color: #808080\">316,861, </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">O: </span><span style=\"color: #808080; text-decoration-color: #808080\">5,874]                                             </span> │\n│                                                                                                                 │\n│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">accuracy: 0.825</span><span style=\"color: #008000; text-decoration-color: #008000\">  </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">stderr: 0.0111</span>                                                                                 │\n│                                                                                                                 │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">Log:</span> <a href=\"logs/2025-03-30T05-41-24+00-00_arc-challenge_3rxBdeeDZHy6PzDrYAc29G.json\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080\">logs/2025-03-30T05-41-24+00-00_arc-challenge_3rxBdeeDZHy6PzDrYAc29G.json</span></a>                                   │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "bf57d77658634f4082413d175fb8ff9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bb243b08a9246ac8e7f9a3a2c24436a": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_232f4971206d4e36856c3a8aa764bd94",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "╭─ \u001b[1marc_challenge (1,172 samples): groq/gemma2-9b-it\u001b[0m ──────────────────────────────────────────────────────────────╮\n│                                                                                        dataset: allenai/ai2_arc │\n│ \u001b[1mtotal time:               \u001b[0m  0:09:56                                                                             │\n│ \u001b[1mopenai/gpt-4o-mini        \u001b[0m  455,777 tokens [\u001b[1mI: \u001b[0m242,368, \u001b[1mCW: \u001b[0m0, \u001b[1mCR: \u001b[0m0, \u001b[1mO: \u001b[0m213,409, \u001b[1mR: \u001b[0m0]                         │\n│ \u001b[1mgroq/gemma2-9b-it         \u001b[0m  325,159 tokens [\u001b[1mI: \u001b[0m317,954, \u001b[1mO: \u001b[0m7,205]                                               │\n│                                                                                                                 │\n│ \u001b[1maccuracy: 0.9\u001b[0m  \u001b[1mstderr: 0.00876\u001b[0m                                                                                  │\n│                                                                                                                 │\n│ \u001b[1mLog:\u001b[0m \u001b]8;id=131653;logs/2025-03-30T05-56-10+00-00_arc-challenge_cAzBxRR8nkzueVodtxxjfT.json\u001b\\logs/2025-03-30T05-56-10+00-00_arc-challenge_cAzBxRR8nkzueVodtxxjfT.json\u001b]8;;\u001b\\                                   │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">arc_challenge (1,172 samples): groq/gemma2-9b-it</span> ──────────────────────────────────────────────────────────────╮\n│      <span style=\"color: #000080; text-decoration-color: #000080\">                                                                                  dataset: allenai/ai2_arc</span> │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">total time:               </span><span style=\"color: #808080; text-decoration-color: #808080\">  0:09:56                                                                            </span> │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">openai/gpt-4o-mini        </span><span style=\"color: #808080; text-decoration-color: #808080\">  455,777 tokens [</span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">I: </span><span style=\"color: #808080; text-decoration-color: #808080\">242,368, </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">CW: </span><span style=\"color: #808080; text-decoration-color: #808080\">0, </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">CR: </span><span style=\"color: #808080; text-decoration-color: #808080\">0, </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">O: </span><span style=\"color: #808080; text-decoration-color: #808080\">213,409, </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">R: </span><span style=\"color: #808080; text-decoration-color: #808080\">0]                        </span> │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">groq/gemma2-9b-it         </span><span style=\"color: #808080; text-decoration-color: #808080\">  325,159 tokens [</span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">I: </span><span style=\"color: #808080; text-decoration-color: #808080\">317,954, </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">O: </span><span style=\"color: #808080; text-decoration-color: #808080\">7,205]                                              </span> │\n│                                                                                                                 │\n│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">accuracy: 0.9</span><span style=\"color: #008000; text-decoration-color: #008000\">  </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">stderr: 0.00876</span>                                                                                  │\n│                                                                                                                 │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">Log:</span> <a href=\"logs/2025-03-30T05-56-10+00-00_arc-challenge_cAzBxRR8nkzueVodtxxjfT.json\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080\">logs/2025-03-30T05-56-10+00-00_arc-challenge_cAzBxRR8nkzueVodtxxjfT.json</span></a>                                   │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "232f4971206d4e36856c3a8aa764bd94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a3d91d29c184d34b263aa448fea2d93": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_3f7f73a0f1ff43cf9c9baa0dcc7ec144",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "╭─ \u001b[1marc_challenge (1,172 samples): groq/gemma2-9b-it\u001b[0m ──────────────────────────────────────────────────────────────╮\n│                                                                                        dataset: allenai/ai2_arc │\n│                                                                                                                 │\n│ ⠿ arc_challenge groq/gemma2-9b-it  ━                                      4%    42/1,172 accuracy: 0.93 0:00:30 │\n│                                                                                                                 │\n│ \u001b[1manthropic:\u001b[0m 9/10  \u001b[1mgroq:\u001b[0m 1/10                                                                 \u001b[1mHTTP retries:\u001b[0m 3,312 │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">arc_challenge (1,172 samples): groq/gemma2-9b-it</span> ──────────────────────────────────────────────────────────────╮\n│      <span style=\"color: #000080; text-decoration-color: #000080\">                                                                                  dataset: allenai/ai2_arc</span> │\n│                                                                                                                 │\n│ <span style=\"color: #000080; text-decoration-color: #000080\">⠿</span> arc_challenge groq/gemma2-9b-it  <span style=\"color: #f92672; text-decoration-color: #f92672\">━</span>                                    <span style=\"color: #800080; text-decoration-color: #800080\">  4%</span>    42/1,172 accuracy: 0.93 <span style=\"color: #808000; text-decoration-color: #808000\">0:00:30</span> │\n│                                                                                                                 │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">anthropic:</span><span style=\"color: #808080; text-decoration-color: #808080\"> 9/10  </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">groq:</span><span style=\"color: #808080; text-decoration-color: #808080\"> 1/10                                                                 </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">HTTP retries:</span><span style=\"color: #808080; text-decoration-color: #808080\"> 3,312</span> │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "3f7f73a0f1ff43cf9c9baa0dcc7ec144": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea85089c2b7d4a0abed6b039aa375a07": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_f8cf5d6f6a7a4bdfbc88e5465468bca6",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "╭─ \u001b[1marc_challenge (1,172 samples): groq/gemma2-9b-it\u001b[0m ──────────────────────────────────────────────────────────────╮\n│                                                                                        dataset: allenai/ai2_arc │\n│                                                                                                                 │\n│ \u001b[1mtotal time:                       \u001b[0m  0:06:57                                                                     │\n│ \u001b[1mgroq/gemma2-9b-it                 \u001b[0m  141,431 tokens [\u001b[1mI: \u001b[0m134,283, \u001b[1mO: \u001b[0m7,148]                                       │\n│                                                                                                                 │\n│ \u001b[1maccuracy: 0.904\u001b[0m  \u001b[1mstderr: 0.00863\u001b[0m                                                                                │\n│                                                                                                                 │\n│ \u001b[1mLog:\u001b[0m \u001b]8;id=232165;logs/2025-04-07T04-40-27+00-00_arc-challenge_PMY8QcjJRTezai8wxAzGuh.json\u001b\\logs/2025-04-07T04-40-27+00-00_arc-challenge_PMY8QcjJRTezai8wxAzGuh.json\u001b]8;;\u001b\\                                   │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">arc_challenge (1,172 samples): groq/gemma2-9b-it</span> ──────────────────────────────────────────────────────────────╮\n│      <span style=\"color: #000080; text-decoration-color: #000080\">                                                                                  dataset: allenai/ai2_arc</span> │\n│                                                                                                                 │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">total time:                       </span><span style=\"color: #808080; text-decoration-color: #808080\">  0:06:57                                                                    </span> │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">groq/gemma2-9b-it                 </span><span style=\"color: #808080; text-decoration-color: #808080\">  141,431 tokens [</span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">I: </span><span style=\"color: #808080; text-decoration-color: #808080\">134,283, </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">O: </span><span style=\"color: #808080; text-decoration-color: #808080\">7,148]                                      </span> │\n│                                                                                                                 │\n│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">accuracy: 0.904</span><span style=\"color: #008000; text-decoration-color: #008000\">  </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">stderr: 0.00863</span>                                                                                │\n│                                                                                                                 │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">Log:</span> <a href=\"logs/2025-04-07T04-40-27+00-00_arc-challenge_PMY8QcjJRTezai8wxAzGuh.json\" target=\"_blank\"><span style=\"color: #000080; text-decoration-color: #000080\">logs/2025-04-07T04-40-27+00-00_arc-challenge_PMY8QcjJRTezai8wxAzGuh.json</span></a>                                   │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "f8cf5d6f6a7a4bdfbc88e5465468bca6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "568fb17326e047e0a951f6c7e0239507": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_2e9ab1d9d2e544ed8643b20bdfb5c018",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "╭─ \u001b[1marc_challenge (1,172 samples): groq/llama3-8b-8192\u001b[0m ────────────────────────────────────────────────────────────╮\n│                                                                                        dataset: allenai/ai2_arc │\n│                                                                                                                 │\n│ ⠿ arc_challenge groq/llama3-8b-8192  ━━━━━━━━━━━━━━━━━━╸                 56%   668/1,172 accuracy: 0.81 0:07:39 │\n│                                                                                                                 │\n│ \u001b[1mgroq:\u001b[0m 10/10                                                                                 \u001b[1mHTTP retries:\u001b[0m 2,635 │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">arc_challenge (1,172 samples): groq/llama3-8b-8192</span> ────────────────────────────────────────────────────────────╮\n│      <span style=\"color: #000080; text-decoration-color: #000080\">                                                                                  dataset: allenai/ai2_arc</span> │\n│                                                                                                                 │\n│ <span style=\"color: #000080; text-decoration-color: #000080\">⠿</span> arc_challenge groq/llama3-8b-8192  <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━╸</span>                <span style=\"color: #800080; text-decoration-color: #800080\"> 56%</span>   668/1,172 accuracy: 0.81 <span style=\"color: #808000; text-decoration-color: #808000\">0:07:39</span> │\n│                                                                                                                 │\n│ <span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">groq:</span><span style=\"color: #808080; text-decoration-color: #808080\"> 10/10                                                                                 </span><span style=\"color: #808080; text-decoration-color: #808080; font-weight: bold\">HTTP retries:</span><span style=\"color: #808080; text-decoration-color: #808080\"> 2,635</span> │\n╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "2e9ab1d9d2e544ed8643b20bdfb5c018": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "requirements.txt"
      ],
      "metadata": {
        "id": "lCDn7X-QqJDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install inspect_ai\n",
        "!pip install git+https://github.com/UKGovernmentBEIS/inspect_evals\n",
        "!pip install openai\n",
        "!pip install google-generativeai\n",
        "!pip install groq\n",
        "!pip install anthropic\n",
        "!pip install langchain\n",
        "!pip install -qU \"langchain[openai]\"\n",
        "!pip install -qU \"langchain[anthropic]\"\n",
        "!pip install -qU \"langchain[groq]\"\n",
        "!pip install -qU \"langchain[google-vertexai]\"\n",
        "!pip install langchain-google-genai"
      ],
      "metadata": {
        "id": "ds9KzIKZrtVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "API Keys"
      ],
      "metadata": {
        "id": "-BtJiYg7qbjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ['ANTHROPIC_API_KEY'] = userdata.get('ANTHROPIC_API_KEY')\n",
        "os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')\n",
        "os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')"
      ],
      "metadata": {
        "id": "KE7pnUShqeS2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive"
      ],
      "metadata": {
        "id": "onC2OR1qqgAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29-SOCMVqkod",
        "outputId": "570c4ecc-ffcc-4b4e-f57d-60811a1db121"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/AISC/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNCsiN4YsU8n",
        "outputId": "a8133d45-d11a-40ab-9e7f-263e4ba531b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AISC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "zxYI-RworDtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from inspect_ai import Task, task, task_with\n",
        "from inspect_ai.dataset import Sample\n",
        "from inspect_ai.solver import generate, solver, TaskState, Generate, system_message, multiple_choice\n",
        "from inspect_ai.solver._multiple_choice import prompt as lprompt\n",
        "from inspect_ai.scorer import exact, choice\n",
        "from inspect_ai import eval\n",
        "from inspect_ai.model import get_model, GenerateConfig, Model, ChatMessageUser\n",
        "from inspect_ai._util.dict import omit\n",
        "from inspect_ai._util.format import format_template\n",
        "from inspect_ai.util import resource"
      ],
      "metadata": {
        "id": "w_9EtlJGrGJk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models"
      ],
      "metadata": {
        "id": "TAj--jYuqrhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_MODEL_1 = get_model('groq/gemma2-9b-it',memoize=False)\n",
        "BASE_MODEL_2 = get_model('groq/llama3-8b-8192',memoize=False)\n",
        "PROMPT_OPTIMIZER_MODEL_1 = get_model('openai/gpt-4o-mini',memoize=False)\n",
        "PROMPT_OPTIMIZER_MODEL_2 = get_model(model='anthropic/claude-3-5-haiku-20241022',memoize=False,config=GenerateConfig(max_retries=2))\n",
        "PROMPT_OPTIMIZER_MODEL_3 = get_model('openai/o3-mini',memoize=False)\n",
        "PROMPT_OPTIMIZER_MODEL_4 = get_model('anthropic/claude-3-7-sonnet-20250219',memoize=False)"
      ],
      "metadata": {
        "id": "-7Pyz1K5qu76"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test if the models were initialized\n",
        "print(BASE_MODEL_1.name, (await BASE_MODEL_1.generate(input=\"Hello World\")).completion)\n",
        "print(BASE_MODEL_2.name, (await BASE_MODEL_2.generate(input=\"Hello World\")).completion)\n",
        "print(PROMPT_OPTIMIZER_MODEL_1.name, (await PROMPT_OPTIMIZER_MODEL_1.generate(input=\"Hello World\")).completion)\n",
        "print(PROMPT_OPTIMIZER_MODEL_2.name, (await PROMPT_OPTIMIZER_MODEL_2.generate(input=\"Hello World\")).completion)\n",
        "print(PROMPT_OPTIMIZER_MODEL_3.name, (await PROMPT_OPTIMIZER_MODEL_3.generate(input=\"Hello World\")).completion)\n",
        "print(PROMPT_OPTIMIZER_MODEL_4.name, (await PROMPT_OPTIMIZER_MODEL_4.generate(input=\"Hello World\")).completion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVhj-cc4LdSb",
        "outputId": "d5e12fdb-4c1f-44b7-e030-f218151f0e48"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gemma2-9b-it Hello there! 👋 \n",
            "\n",
            "How can I help you today? 😊\n",
            "\n",
            "llama3-8b-8192 Hello World! Nice to meet you! How can I help you today?\n",
            "gpt-4o-mini Hello! How can I assist you today?\n",
            "claude-3-5-haiku-20241022 Hello! How are you doing today? Is there anything I can help you with?\n",
            "o3-mini Hello there! \"Hello World\" is a timeless greeting—often used as the first step when learning a new programming language. How can I assist you today?\n",
            "claude-3-7-sonnet-20250219 Hello! It's nice to meet you. I'm an AI assistant ready to help with information, answer questions, or just chat. Is there something specific you'd like to talk about or any way I can assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Solver"
      ],
      "metadata": {
        "id": "OApjPJ-7qxp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@solver\n",
        "def custom_solver(template: str, optimizer_model: Model):\n",
        "    prompt_template = resource(template)\n",
        "    async def solve(state: TaskState, generate: Generate):\n",
        "      try:\n",
        "        nonlocal optimizer_model\n",
        "        prompt = state.user_prompt\n",
        "        kwargs = omit(state.metadata | state.store._data, [\"prompt\"])\n",
        "        prompt_optimizer_input = format_template(prompt_template, {\"prompt\": prompt} | kwargs)\n",
        "        response = await optimizer_model.generate(input=prompt_optimizer_input, config=GenerateConfig(max_retries=2,timeout=5))\n",
        "        prompt.text = format_template(response.completion, {\"prompt\": prompt.text} | kwargs)\n",
        "        return state\n",
        "      except Exception as e:\n",
        "        print(response.completion)\n",
        "        return state\n",
        "    return solve"
      ],
      "metadata": {
        "id": "D4OP9_gIq2wV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Solver Langchain Agent"
      ],
      "metadata": {
        "id": "rsGQ29oeNTU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/UKGovernmentBEIS/inspect_ai/blob/1f6162992c01b0d258377527c2b8473821c56352/examples/bridge/langchain/agent.py\n",
        "# https://python.langchain.com/docs/tutorials/agents/\n",
        "\n",
        "# Import relevant functionality\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "ro8SST_2NV6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Scorer (Not needed atm)"
      ],
      "metadata": {
        "id": "QdqKCsmuq34z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sXbiXtXxq7A0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eval Tasks"
      ],
      "metadata": {
        "id": "DNcaMEgfq7li"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from inspect_evals import arc\n",
        "from inspect_evals import agieval\n",
        "from inspect_evals import mmlu_pro\n",
        "\n",
        "arc_evaluation_task = arc.arc_challenge()\n",
        "agie_english_task= agieval.agie_lsat_ar()\n",
        "agie_math_task = agieval.agie_math()\n",
        "mmlu_pro_task = mmlu_pro.mmlu_pro()"
      ],
      "metadata": {
        "id": "zQFYIQDBq957"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/UKGovernmentBEIS/inspect_evals/blob/main/src/inspect_evals/agieval/utils.py\n",
        "MULTIPLE_CHOICE_TEMPLATE_EN = r\"\"\"\n",
        "{fewshot_string}\n",
        "\n",
        "Answer the following multiple choice question. The last line of your response should be of the following format: 'ANSWER: $LETTER' (without quotes) where LETTER is one of {letters}. {cot_string}\n",
        "\n",
        "{question}\n",
        "\n",
        "{choices}\n",
        "\"\"\".strip()"
      ],
      "metadata": {
        "id": "lf-A_efykBgl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eval without scaffolding"
      ],
      "metadata": {
        "id": "snZDb9j-q_Mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval(\n",
        "    tasks=arc_evaluation_task,\n",
        "    model=BASE_MODEL_1,\n",
        "    solver=[\n",
        "        multiple_choice(),\n",
        "    ],\n",
        "    log_dir='./logs/',\n",
        "    log_format='json',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193,
          "referenced_widgets": [
            "ea85089c2b7d4a0abed6b039aa375a07",
            "f8cf5d6f6a7a4bdfbc88e5465468bca6"
          ]
        },
        "id": "KAIhl-MNrBt_",
        "outputId": "2ed20fa3-912f-4165-d929-142ff4500d26"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea85089c2b7d4a0abed6b039aa375a07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval(\n",
        "    tasks=agie_english_task,\n",
        "    model=BASE_MODEL_1,\n",
        "    solver=[\n",
        "        multiple_choice(template=MULTIPLE_CHOICE_TEMPLATE_EN),\n",
        "        generate(),\n",
        "    ],\n",
        "    log_dir='./logs/',\n",
        "    log_format='json',\n",
        ")"
      ],
      "metadata": {
        "id": "Gr8jcHNVi6YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval(\n",
        "    tasks=agie_math_task,\n",
        "    model=BASE_MODEL_1,\n",
        "    solver=[\n",
        "        multiple_choice(template=MULTIPLE_CHOICE_TEMPLATE_EN),\n",
        "        generate(),\n",
        "    ],\n",
        "    log_dir='./logs/',\n",
        "    log_format='json',\n",
        ")"
      ],
      "metadata": {
        "id": "KdYe-OFqi8w1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval(\n",
        "    tasks=arc_evaluation_task,\n",
        "    model=BASE_MODEL_2,\n",
        "    solver=[\n",
        "        multiple_choice(),\n",
        "    ],\n",
        "    log_dir='./logs/',\n",
        "    log_format='json',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "568fb17326e047e0a951f6c7e0239507",
            "2e9ab1d9d2e544ed8643b20bdfb5c018"
          ]
        },
        "id": "PXplCykv51ui",
        "outputId": "b5a40ce3-b609-4005-c18e-ed920b6eec14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "568fb17326e047e0a951f6c7e0239507"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval(\n",
        "    tasks=agie_english_task,\n",
        "    model=BASE_MODEL_2,\n",
        "    solver=[\n",
        "        multiple_choice(template=MULTIPLE_CHOICE_TEMPLATE_EN),\n",
        "        generate(),\n",
        "    ],\n",
        "    log_dir='./logs/',\n",
        "    log_format='json',\n",
        ")"
      ],
      "metadata": {
        "id": "EbgHg1ZNkvtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eval on prompt optimizer model (openai/gpt-4o-mini)"
      ],
      "metadata": {
        "id": "unHzst00TjiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval(\n",
        "    tasks=arc_evaluation_task,\n",
        "    model=PROMPT_OPTIMIZER_MODEL_1,\n",
        "    solver=[\n",
        "        multiple_choice(),\n",
        "    ],\n",
        "    log_dir='./logs/',\n",
        "    log_format='json',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193,
          "referenced_widgets": [
            "1c91a9d776394ddb82585a8421c8f5e0",
            "0d830094452b4d3783bc55f15b24c715"
          ]
        },
        "id": "vtlz_g6gTmy5",
        "outputId": "02aa9c2e-8492-4218-c9d8-ca50d1d2b484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c91a9d776394ddb82585a8421c8f5e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eval on prompt optimizer model (anthropic/claude-3-5-haiku-20241022)"
      ],
      "metadata": {
        "id": "H9Z1QqOXRn9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval(\n",
        "    tasks=arc_evaluation_task,\n",
        "    model=PROMPT_OPTIMIZER_MODEL_2,\n",
        "    solver=[\n",
        "        multiple_choice(),\n",
        "    ],\n",
        "    log_dir='./logs/',\n",
        "    log_format='json',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193,
          "referenced_widgets": [
            "47a6bc62a5cc448d8ce6bc81cc2d7414",
            "a9a74974747c4edf9b2e9f604f16be75"
          ]
        },
        "id": "OnIYdB8KM7bn",
        "outputId": "e984640b-8e92-47e6-f819-841f0cfd4c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47a6bc62a5cc448d8ce6bc81cc2d7414"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eval on prompt optimizer model (openai/o3-mini)"
      ],
      "metadata": {
        "id": "sLeYUURFlSyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval(\n",
        "    tasks=arc_evaluation_task,\n",
        "    model=PROMPT_OPTIMIZER_MODEL_3,\n",
        "    solver=[\n",
        "        multiple_choice(),\n",
        "    ],\n",
        "    log_dir='./logs/',\n",
        "    log_format='json',\n",
        ")"
      ],
      "metadata": {
        "id": "zfwz9ARMlJZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eval on prompt optimizer model (anthropic/claude-3-7-sonnet-20250219)"
      ],
      "metadata": {
        "id": "rKUSkXXWlZvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval(\n",
        "    tasks=arc_evaluation_task,\n",
        "    model=PROMPT_OPTIMIZER_MODEL_4,\n",
        "    solver=[\n",
        "        multiple_choice(),\n",
        "    ],\n",
        "    log_dir='./logs/',\n",
        "    log_format='json',\n",
        ")"
      ],
      "metadata": {
        "id": "7Zmzz_0HlJBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eval with scaffolding"
      ],
      "metadata": {
        "id": "nyqUKnrYrNKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "gpt-4o-mini + llama3-8b-8192 as base model"
      ],
      "metadata": {
        "id": "zhmXGHm6SCrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaffolded_evaluation_task = task_with(\n",
        "    task=arc.arc_challenge(),\n",
        "    solver=[\n",
        "        custom_solver('./prompt_templates/generated_knowledge.txt', PROMPT_OPTIMIZER_MODEL_1),\n",
        "        multiple_choice(),\n",
        "    ],\n",
        ")\n",
        "\n",
        "eval(\n",
        "    tasks=scaffolded_evaluation_task,\n",
        "    model=BASE_MODEL_2,\n",
        "    log_dir='./logs/',\n",
        "    log_format='json',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193,
          "referenced_widgets": [
            "ea32df1816594e9d89f26e891b11060b",
            "bf57d77658634f4082413d175fb8ff9c"
          ]
        },
        "id": "wWuyGlaQR_9K",
        "outputId": "649f5a21-9043-4af6-937f-c6e3af9500d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea32df1816594e9d89f26e891b11060b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gpt-4o-mini + gemma as base model"
      ],
      "metadata": {
        "id": "4-1CyouodorP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaffolded_evaluation_task = task_with(\n",
        "    task=arc.arc_challenge(),\n",
        "    solver=[\n",
        "        custom_solver('./prompt_templates/generated_knowledge.txt', PROMPT_OPTIMIZER_MODEL_1),\n",
        "        multiple_choice(),\n",
        "    ],\n",
        ")\n",
        "\n",
        "eval(\n",
        "    tasks=scaffolded_evaluation_task,\n",
        "    model=BASE_MODEL_1,\n",
        "    log_dir='./logs/',\n",
        "    log_format='json',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193,
          "referenced_widgets": [
            "5bb243b08a9246ac8e7f9a3a2c24436a",
            "232f4971206d4e36856c3a8aa764bd94"
          ]
        },
        "id": "fwF8trQ0dxLk",
        "outputId": "3664f481-27cc-42f9-94d3-5973beeb6ad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bb243b08a9246ac8e7f9a3a2c24436a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "claude-haiku + llama3-8b-8192 as base model"
      ],
      "metadata": {
        "id": "sKWFOkRDSFJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaffolded_evaluation_task = task_with(\n",
        "    task=arc.arc_challenge(),\n",
        "    solver=[\n",
        "        custom_solver('./prompt_templates/generated_knowledge.txt', PROMPT_OPTIMIZER_MODEL_2),\n",
        "        multiple_choice(),\n",
        "    ],\n",
        ")\n",
        "\n",
        "eval(\n",
        "    tasks=scaffolded_evaluation_task,\n",
        "    model=BASE_MODEL_2,\n",
        "    log_dir='./logs/',\n",
        "    log_format='json',\n",
        ")"
      ],
      "metadata": {
        "id": "VpDwmiasrWJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "claude-haiku + gemma as base model"
      ],
      "metadata": {
        "id": "1whTYWUWdeKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaffolded_evaluation_task = task_with(\n",
        "    task=arc.arc_challenge(),\n",
        "    solver=[\n",
        "        custom_solver('./prompt_templates/generated_knowledge.txt', PROMPT_OPTIMIZER_MODEL_2),\n",
        "        multiple_choice(),\n",
        "    ],\n",
        ")\n",
        "\n",
        "eval(\n",
        "    tasks=scaffolded_evaluation_task,\n",
        "    model=BASE_MODEL_1,\n",
        "    log_dir='./logs/',\n",
        "    log_format='json',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "6a3d91d29c184d34b263aa448fea2d93",
            "3f7f73a0f1ff43cf9c9baa0dcc7ec144"
          ]
        },
        "id": "oJypYkjadfNN",
        "outputId": "78723644-389c-4477-f246-755c1c34a41b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a3d91d29c184d34b263aa448fea2d93"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "o3-mini + llama3-8b-8192 as base model"
      ],
      "metadata": {
        "id": "mqQTFImsls7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaffolded_evaluation_task = task_with(\n",
        "    task=arc.arc_challenge(),\n",
        "    solver=[\n",
        "        custom_solver('./prompt_templates/generated_knowledge.txt', PROMPT_OPTIMIZER_MODEL_3),\n",
        "        multiple_choice(),\n",
        "    ],\n",
        ")\n",
        "\n",
        "eval(\n",
        "    tasks=scaffolded_evaluation_task,\n",
        "    model=BASE_MODEL_2,\n",
        "    log_dir='./logs/',\n",
        "    log_format='json',\n",
        ")"
      ],
      "metadata": {
        "id": "q-LPJRtqltYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "o3-mini + gemma as base model"
      ],
      "metadata": {
        "id": "UWR12rwMl85N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaffolded_evaluation_task = task_with(\n",
        "    task=arc.arc_challenge(),\n",
        "    solver=[\n",
        "        custom_solver('./prompt_templates/generated_knowledge.txt', PROMPT_OPTIMIZER_MODEL_3),\n",
        "        multiple_choice(),\n",
        "    ],\n",
        ")\n",
        "\n",
        "eval(\n",
        "    tasks=scaffolded_evaluation_task,\n",
        "    model=BASE_MODEL_1,\n",
        "    log_dir='./logs/',\n",
        "    log_format='json',\n",
        ")"
      ],
      "metadata": {
        "id": "ceSIi1uEl9SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "claude-sonet + llama3-8b-8192 as base model"
      ],
      "metadata": {
        "id": "4AFTIhsGlttj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaffolded_evaluation_task = task_with(\n",
        "    task=arc.arc_challenge(),\n",
        "    solver=[\n",
        "        custom_solver('./prompt_templates/generated_knowledge.txt', PROMPT_OPTIMIZER_MODEL_4),\n",
        "        multiple_choice(),\n",
        "    ],\n",
        ")\n",
        "\n",
        "eval(\n",
        "    tasks=scaffolded_evaluation_task,\n",
        "    model=BASE_MODEL_2,\n",
        "    log_dir='./logs/',\n",
        "    log_format='json',\n",
        ")"
      ],
      "metadata": {
        "id": "OymjA_baluIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "claude-sonet + gemma as base model"
      ],
      "metadata": {
        "id": "II_Aqf2iluzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaffolded_evaluation_task = task_with(\n",
        "    task=arc.arc_challenge(),\n",
        "    solver=[\n",
        "        custom_solver('./prompt_templates/generated_knowledge.txt', PROMPT_OPTIMIZER_MODEL_4),\n",
        "        multiple_choice(),\n",
        "    ],\n",
        ")\n",
        "\n",
        "eval(\n",
        "    tasks=scaffolded_evaluation_task,\n",
        "    model=BASE_MODEL_1,\n",
        "    log_dir='./logs/',\n",
        "    log_format='json',\n",
        ")"
      ],
      "metadata": {
        "id": "yFyuf9TqlvJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison"
      ],
      "metadata": {
        "id": "zJppM8TdrW0S"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lfWyZufsrZi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpreting Results"
      ],
      "metadata": {
        "id": "INa6U0d4raNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    with open('./logs/2025-03-22T14-43-31+00-00_arc-challenge_nxg7KJPr4jbPPqsCtsXMtT.json','r') as file:\n",
        "        data = json.load(file)\n",
        "    outputs = {}\n",
        "    for sample in data['samples']:\n",
        "        outputs[sample['input']] = {\n",
        "            'enhanced_prompt': sample['messages'][1]['content'] # The assistant response\n",
        "        }\n",
        "    with open('./enhanced_prompts/hello_world1.json','w+') as file:\n",
        "        json.dump(outputs, file, indent=4)\n"
      ],
      "metadata": {
        "id": "3w99QolnrhY8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}