{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from groq import Groq\n",
    "from typing import Any, Literal, Union\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of AI evals in 20 words\"\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"models_from_hf/tokenizers/{model_name}\")\n",
    "model = AutoModelForCausalLM.from_pretrained(f\"models_from_hf/models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[128000,   8144,    264,  33894,    389,    364,  22333,  21579,      6,\n",
      "            369,   6980,     13,    362,  33894,    374,    264,  32465,  18528,\n",
      "             11,   8965,   5439,    304,  33487,   1376,     11,    430,   5829,\n",
      "           1664,  11843,   8477,   4339,    323,  32847,    311,  20599,    264,\n",
      "           7438,    477,   4623,     13,  14128,  12116,    649,    387,   5439,\n",
      "            304,   1690,   2204,   9404,     11,    505,   1949,  33487,    311,\n",
      "           4538,  53961,     13,  14128,  12116,    649,   1101,    387,   5439,\n",
      "            304,    264,   3230,  17779,     11,   1778,    439,    264,   3021,\n",
      "          33894,    477,    264,   6520,  39342,     13,    578,   1925,   7580,\n",
      "            315,    264,  33894,    374,    311,  19570,    264,   1984,    477,\n",
      "           4623,    311,    279,   6742,     13,  14128,  12116,    649,    387,\n",
      "           1511,    311,   3237,  16024,     11,  11555,     11,    477,  11704,\n",
      "             13]])\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a poem on 'Machine Learning'\"\n",
    "pembedding = tokenizer(prompt,return_tensors=\"pt\")\n",
    "response = model.generate(**pembedding,max_new_tokens=100)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|>Write a poem on 'Machine Learning' for kids. A poem is a literary composition, generally written in verse form, that uses well-chosen words and phrases to convey a meaning or idea. Poems can be written in many different styles, from free verse to sonnets. Poems can also be written in a specific genre, such as a love poem or a haiku. The main purpose of a poem is to communicate a message or idea to the reader. Poems can be used to express feelings, thoughts, or experiences.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(response[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mldev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
